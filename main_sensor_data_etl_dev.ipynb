{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Summary\n",
    "\n",
    "**Objective**\n",
    "\n",
    "We have a sensor data source in JSON format from our IOT devices. We would like to create an analytics data lake and allow analyst to query the data.\n",
    "\n",
    "**Challenge**\n",
    "\n",
    "The raw data are complex JSON, we would like to flatten it out into parquet."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 1. Preparation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1.1 Import Libraries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Standard Library\n",
    "import os\n",
    "import sys\n",
    "import dataclasses\n",
    "\n",
    "# PySpark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Glue\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue import DynamicFrame\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from awsglue.job import Job\n",
    "\n",
    "spark_ses = SparkSession.builder.getOrCreate()\n",
    "# spark_ctx = SparkContext.getOrCreate()\n",
    "# glue_ctx = GlueContext(spark_ctx)\n",
    "# spark_ses = glue_ctx.spark_session"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pdf = spark_ses.createDataFrame(\n",
    "    [\n",
    "        (\"e-1\", \"2000-01-01T08:30:00\", {\"temperature\": 78}),\n",
    "        (\"e-2\", \"2000-01-01T08:30:00\", {\"temperature\": 56}),\n",
    "        (\"e-3\", \"2000-01-01T08:30:00\", {\"temperature\": 69}),\n",
    "    ],\n",
    "    (\"device_id\", \"time\", \"measurement\"),\n",
    ")\n",
    "pdf.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1.2 Detect the Current Runtime\n",
    "\n",
    "In development phase, we would like to use interactive Jupyter Notebook and small sample data as the source. So we can focus on the transformation logics and see live results faster."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a019e7570abe4901b363389bcbe97b6a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Runtime Information =================================================\n",
      "IS_CONTAINER = True\n",
      "IS_GLUE_NOTEBOOK = False\n",
      "IS_GLUE_JOB = False"
     ]
    }
   ],
   "source": [
    "IS_CONTAINER = False\n",
    "IS_GLUE_NOTEBOOK = False\n",
    "IS_GLUE_JOB = False\n",
    "\n",
    "# The Glue Job run always has \"--JOB_RUN_ID\" in arguments\n",
    "if \"--JOB_RUN_ID\" in sys.argv:\n",
    "    IS_GLUE_JOB = True\n",
    "# We always pass in a custom env var in \"docker run ...\" command\n",
    "elif os.environ.get(\"IS_CONTAINER\", \"n\") == \"y\":\n",
    "    IS_CONTAINER = True\n",
    "else:\n",
    "    IS_GLUE_NOTEBOOK = True\n",
    "\n",
    "\n",
    "def print_header(msg: str):\n",
    "    msg = f\" {msg} \"\n",
    "    bar = \"=\" * 10\n",
    "    print(f\"{bar}{msg:=<70}\")\n",
    "\n",
    "\n",
    "print_header(\"Step 1. Preparation\")\n",
    "print(\"Runtime Information:\")\n",
    "print(\"\")\n",
    "print(f\"IS_CONTAINER = {IS_CONTAINER}\")\n",
    "print(f\"IS_GLUE_NOTEBOOK = {IS_GLUE_NOTEBOOK}\")\n",
    "print(f\"IS_GLUE_JOB = {IS_GLUE_JOB}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3af280927bf942b8917dd6fd65a64221"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import custom libraries\n",
    "if IS_CONTAINER:\n",
    "    more_path = [\n",
    "        \"/home/glue_user/workspace/jupyter_workspace\",\n",
    "        \"/home/glue_user/workspace/extra_python_path\",\n",
    "    ]\n",
    "    for path in more_path:\n",
    "        if path not in sys.path:\n",
    "            sys.path.append(path)\n",
    "\n",
    "from gluelib_json_to_parquet.transform_dataframe import json_to_parquet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dfe850fa782e4a659c251f19038f4a6d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize Job (if in glue job runtime)\n",
    "if IS_GLUE_JOB:\n",
    "    args = getResolvedOptions(\n",
    "        sys.argv,\n",
    "        [\n",
    "            \"JOB_NAME\",\n",
    "            \"data_source_s3_uri\",\n",
    "        ]\n",
    "    )\n",
    "    print(\"Resolved Arguments:\")\n",
    "    print(\"\")\n",
    "    for key, value in args.items():\n",
    "        print(f\"{key} = {value!r}\")\n",
    "    job = Job(glue_ctx)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1.3 Declare Parameter\n",
    "\n",
    "We declared a data class to store all required Job Parameters.\n",
    "\n",
    "In production, most of parameter should be passed in as [Job Arguments](https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-crawler-pyspark-extensions-get-resolved-options.html).\n",
    "\n",
    "In development phase, we would like to hardcode the value so we can focus on the core logics.\n",
    "\n",
    "We could use a simple ``if else`` statement to use different logic to initialize the Job Parameters Python object."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "04ebe4c754a943d0a318c013a7f0659f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@dataclasses.dataclass\n",
    "class Param:\n",
    "    data_source_s3_uri: str = \"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1.4 Resolve Parameter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d47df95eba16475b9a7174a094e4833b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if IS_CONTAINER or IS_GLUE_NOTEBOOK:\n",
    "    param = Param(\n",
    "        data_source_s3_uri=\"s3://501105007192-us-east-1-data/projects/gluelib_json_to_parquet/data/sensors/\"\n",
    "    )\n",
    "else:\n",
    "    param = Param(\n",
    "        data_source_s3_uri=args[\"data_source_s3_uri\"],\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 2. Read The Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "43e71e7f1feb4f148f2db60b018f8c80"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Step 2. Read the data ==============================================="
     ]
    }
   ],
   "source": [
    "print_header(\"Step 2. Read the data\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2.1 Read Sensor Data\n",
    "\n",
    "In most of ETL job, we need to read all required data into dataframe. In this section, we focus on reading the data from different data source.\n",
    "\n",
    "**Use Small Data in Dev**\n",
    "\n",
    "The Glue Job is designed for big data processing. However in ETL development phase, the most creative part is the data wrangling. Debugging with big data is not only very expansive and also very NON-interactive. In development phase, I recommend to use small data with similar data characters for development."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "523abf0fce8c47f3bfb633cae6b71d7e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fake_sensor_data() -> DynamicFrame:\n",
    "    \"\"\"\n",
    "    Fake the sensor data source for dev.\n",
    "    \"\"\"\n",
    "    pdf = spark_ses.createDataFrame(\n",
    "        [\n",
    "            (\"e-1\", \"2000-01-01T08:30:00\", {\"temperature\": 78}),\n",
    "            (\"e-2\", \"2000-01-01T08:30:00\", {\"temperature\": 56}),\n",
    "            (\"e-3\", \"2000-01-01T08:30:00\", {\"temperature\": 69}),\n",
    "        ],\n",
    "        (\"device_id\", \"time\", \"measurement\"),\n",
    "    )\n",
    "    return DynamicFrame.fromDF(pdf, glue_ctx, \"gdf_sensor\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34edc86507714557a44514f2c65fd6fb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def read_sensor_data_from_s3() -> DynamicFrame:\n",
    "    \"\"\"\n",
    "    Read data from AWS S3 bucket\n",
    "    \"\"\"\n",
    "    return glue_ctx.create_dynamic_frame.from_options(\n",
    "        connection_type=\"s3\",\n",
    "        connection_options=dict(\n",
    "            paths=[\n",
    "                param.data_source_s3_uri,\n",
    "            ],\n",
    "            recurse=True\n",
    "        ),\n",
    "        format=\"json\",\n",
    "        format_options=dict(multiLine=\"true\"),\n",
    "        transformation_ctx=\"gdf\",\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8e3a54a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f1e319338d545c894273aeb1114f2ca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if IS_CONTAINER or IS_GLUE_NOTEBOOK:\n",
    "    gdf_sensor = fake_sensor_data()\n",
    "else:\n",
    "    gdf_sensor = read_sensor_data_from_s3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0f9622a754404b56a4400814fc8c9d37"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-------------------+\n",
      "|device_id|               time|        measurement|\n",
      "+---------+-------------------+-------------------+\n",
      "|      e-1|2000-01-01T08:30:00|{temperature -> 78}|\n",
      "|      e-2|2000-01-01T08:30:00|{temperature -> 56}|\n",
      "|      e-3|2000-01-01T08:30:00|{temperature -> 69}|\n",
      "+---------+-------------------+-------------------+"
     ]
    }
   ],
   "source": [
    "gdf_sensor.toDF().show(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 3. Transform The Data\n",
    "\n",
    "In this section, we focus on transform the data into desired schema, format."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "29d7952007de40a8aa6614c9fbb3c4d3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Step 3. Transform the data =========================================="
     ]
    }
   ],
   "source": [
    "print_header(\"Step 3. Transform the data\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d452b5b0ac0c426c9c82a54c124858c5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gdf_sensor_unnested = json_to_parquet(gdf_sensor, \"gdf_sensor\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce7735879ed8436cbfbc90afac5cc4b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-----------------------+\n",
      "|device_id|               time|measurement.temperature|\n",
      "+---------+-------------------+-----------------------+\n",
      "|      e-1|2000-01-01T08:30:00|                     78|\n",
      "|      e-2|2000-01-01T08:30:00|                     56|\n",
      "|      e-3|2000-01-01T08:30:00|                     69|\n",
      "+---------+-------------------+-----------------------+"
     ]
    }
   ],
   "source": [
    "gdf_sensor_unnested.toDF().show(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 4. Write the Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da3a5271f9bd4ec3b5af766fdd1b6485"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Step 4. Write the data =============================================="
     ]
    }
   ],
   "source": [
    "print_header(\"Step 4. Write the data\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "62ccc278517941d584d13ba11a12e801"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dump your data to desired location in desired format"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 5. Clean Up"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ddaa3d3d8aa94a23b79a23738d976004"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Step 5. Clean Up ===================================================="
     ]
    }
   ],
   "source": [
    "print_header(\"Step 5. Clean Up\")\n",
    "if IS_GLUE_JOB:\n",
    "    job.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Glue Spark - Local (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}